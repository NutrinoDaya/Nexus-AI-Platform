# NexusAI Platform - System Configuration
# Production-ready configuration for modular AI inference platform

system:
  name: "NexusAI Platform"
  version: "1.0.0"
  description: "Advanced modular AI inference platform supporting multiple model types"
  environment: "production"
  
api:
  host: "0.0.0.0"
  port: 8000
  workers: 8
  timeout: 120
  keepalive: 75
  limit_concurrency: 1000
  backlog: 2048
  cors:
    enabled: true
    origins:
      - "http://localhost:3000"
      - "http://localhost:5173"
      - "https://*.nexusai.io"
    methods: ["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]
    headers: ["*"]
  
security:
  secret_key: "${SECRET_KEY}"
  algorithm: "HS256"
  access_token_expire_minutes: 60
  refresh_token_expire_days: 30
  password_min_length: 8
  require_email_verification: true
  max_login_attempts: 5
  lockout_duration_minutes: 15
  
database:
  url: "${DATABASE_URL}"
  pool_size: 50
  max_overflow: 25
  pool_timeout: 10
  pool_recycle: 1800
  pool_pre_ping: true
  echo: false
  
redis:
  host: "${REDIS_HOST:redis}"
  port: 6379
  db: 0
  password: "${REDIS_PASSWORD}"
  max_connections: 100
  decode_responses: true
  socket_keepalive: true
  socket_connect_timeout: 5
  
storage:
  type: "minio"
  endpoint: "${MINIO_ENDPOINT:minio:9000}"
  access_key: "${MINIO_ACCESS_KEY}"
  secret_key: "${MINIO_SECRET_KEY}"
  secure: false
  region: "us-east-1"
  buckets:
    models: "nexusai-models"
    inference_inputs: "nexusai-inputs"
    inference_outputs: "nexusai-outputs"
    cameras: "nexusai-cameras"
    datasets: "nexusai-datasets"
    
celery:
  broker_url: "${CELERY_BROKER_URL:redis://redis:6379/1}"
  result_backend: "${CELERY_RESULT_BACKEND:redis://redis:6379/2}"
  task_serializer: "json"
  result_serializer: "json"
  accept_content: ["json"]
  timezone: "UTC"
  enable_utc: true
  task_track_started: true
  task_time_limit: 3600
  task_soft_time_limit: 3300
  worker_prefetch_multiplier: 4
  worker_max_tasks_per_child: 100
  worker_concurrency: 8
  
monitoring:
  prometheus:
    enabled: true
    port: 9090
  jaeger:
    enabled: true
    host: "jaeger"
    port: 6831
  logging:
    level: "INFO"
    format: "json"
    file_path: "/var/log/nexusai/app.log"
    max_bytes: 104857600  # 100MB
    backup_count: 10
    
rate_limiting:
  enabled: true
  storage: "redis"
  default_limits:
    - "100/minute"
    - "1000/hour"
    - "10000/day"
  endpoints:
    "/api/v1/inference/predict":
      - "50/minute"
      - "500/hour"
    "/api/v1/auth/login":
      - "5/minute"
      - "20/hour"
    "/api/v1/models/upload":
      - "10/hour"
      
features:
  model_types:
    - pytorch
    - onnx
    - tensorrt
    - openvino
    - tensorflow
  inference_modes:
    - synchronous
    - asynchronous
    - batch
    - streaming
  supported_tasks:
    - object_detection
    - instance_segmentation
    - image_classification
    - pose_estimation
    - object_tracking
    - facial_recognition
    - ocr
    - custom
  plugins:
    enabled: true
    directory: "/app/plugins"
    auto_discover: true
    reload_interval: 300  # seconds
